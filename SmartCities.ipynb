{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYq/rJfQtaWRY8tGFDuz37",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romip111/hackathongrupo11/blob/main/SmartCities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98dIbcGBeTCD",
        "outputId": "81d138aa-5606-4708-fc05-46712c565d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Instalando librer√≠as ---\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.121.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.49.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.11.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "--- Librer√≠as instaladas ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Instalando librer√≠as ---\")\n",
        "!pip install fastapi uvicorn \"rank_bm25\" openai joblib scikit-learn streamlit pyngrok \"openai>=1.0.0\" pandas --upgrade\n",
        "print(\"--- Librer√≠as instaladas ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.makedirs(\"api\", exist_ok=True)\n",
        "os.makedirs(\"app\", exist_ok=True)\n",
        "os.makedirs(\"src\", exist_ok=True)\n",
        "os.makedirs(\"kb\", exist_ok=True)\n",
        "print(\"--- Carpetas creadas ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4SjYC52eYqv",
        "outputId": "dad74b4d-51af-4701-9219-09b00dfa79f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Carpetas creadas ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --- Celda 5: src/rag.py (El buscador del RAG) ---\n",
        "%%writefile src/rag.py\n",
        "import os\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "KB_DIR = 'kb'\n",
        "corpus = []\n",
        "corpus_citas = []\n",
        "\n",
        "try:\n",
        "    for filename in os.listdir(KB_DIR):\n",
        "        if filename.endswith(\".md\"):\n",
        "            filepath = os.path.join(KB_DIR, filename)\n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                contenido = f.read()\n",
        "                corpus.append(contenido)\n",
        "                corpus_citas.append(filename)\n",
        "\n",
        "    tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    print(f\"Indexaci√≥n BM25 completada. {len(corpus)} documentos cargados desde /kb.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error al cargar KB: {e}\")\n",
        "    bm25 = None\n",
        "\n",
        "def buscar_en_kb(query: str, top_k: int = 3) -> list[dict]:\n",
        "    if bm25 is None: return []\n",
        "    tokenized_query = query.split(\" \")\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
        "\n",
        "    resultados = []\n",
        "    for i in top_indexes:\n",
        "        if scores[i] > 0:\n",
        "            resultados.append({\"cita\": corpus_citas[i], \"contenido\": corpus[i]})\n",
        "    return resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI7fkgFrw5WS",
        "outputId": "f69a891c-fd34-4544-95cd-b33631e87a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/rag.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Celda 6: src/prompts.py (El guion del Coach) ---\n",
        "%%writefile src/prompts.py\n",
        "def get_coach_prompt(query_riesgo: str, contexto_kb: list[dict]) -> str:\n",
        "    contexto_str = \"\"\n",
        "    for i, doc in enumerate(contexto_kb):\n",
        "        contexto_str += f\"\\n--- Contexto Verificado {i+1} (Cita: {doc['cita']}) ---\\n\"\n",
        "        contexto_str += doc['contenido']\n",
        "        contexto_str += \"\\n--- Fin Contexto {i+1} ---\"\n",
        "\n",
        "    prompt_template = f\"\"\"\n",
        "Eres un \"Coach\" experto en desarrollo vial (Desaf√≠o Duoc UC).\n",
        "Tu tarea es generar un plan de acci√≥n para reducir accidentes.\n",
        "\n",
        "REGLAS OBLIGATORIAS (R√∫brica):\n",
        "1. Basa tu respuesta √öNICAMENTE en el 'Contexto Verificado' proporcionado.\n",
        "2. Cita tus fuentes EXACTAMENTE como te las entrego (ej. \"Cita: nombre_archivo.md\").\n",
        "3. NUNCA alucines fuentes o informaci√≥n fuera del contexto.\n",
        "4. Valora las diferentes opciones seg√∫n su impacto (econ√≥mico, temporal, etc.).\n",
        "\n",
        "---\n",
        "FACTORES DE RIESGO IDENTIFICADOS:\n",
        "{query_riesgo}\n",
        "\n",
        "---\n",
        "CONTEXTO VERIFICADO (Extra√≠do de tu base /kb):\n",
        "{contexto_str}\n",
        "---\n",
        "\n",
        "Genera el \"Plan de Acci√≥n\" para reducir futuras ocurrencias. Sigue todas las reglas:\n",
        "\"\"\"\n",
        "    return prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-PijHImw_XP",
        "outputId": "e76dc823-34d4-42ce-8162-644a3b063a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/prompts.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Celda 7: api/main.py (La API de FastAPI) ---\n",
        "%%writefile api/main.py\n",
        "import os\n",
        "import sys\n",
        "import joblib\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Any\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "import pandas as pd # Importante para pre-procesar\n",
        "\n",
        "# A√±adimos /content al path para que pueda encontrar 'src'\n",
        "sys.path.append('/content')\n",
        "from src.rag import buscar_en_kb\n",
        "from src.prompts import get_coach_prompt\n",
        "import openai\n",
        "\n",
        "# --- Configuraci√≥n y Carga de Modelos ---\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if openai.api_key is None: raise ValueError(\"Key no encontrada\")\n",
        "    print(\"OpenAI API Key cargada.\")\n",
        "except:\n",
        "    print(\"ERROR: No se encontr√≥ el Secret 'OPENAI_API_KEY'.\")\n",
        "\n",
        "app = FastAPI(title=\"Optimizador de Rutas - Hackathon Duoc UC\")\n",
        "\n",
        "try:\n",
        "    model = joblib.load(\"modelo_riesgo.joblib\")\n",
        "    print(\"‚úÖ Modelo ML (modelo_riesgo.joblib) cargado.\")\n",
        "except Exception as e:\n",
        "    model = None\n",
        "    print(f\"üö® ERROR AL CARGAR MODELO: {e}\")\n",
        "\n",
        "# =================================================================\n",
        "# 1. FUNCI√ìN DE PRE-PROCESAMIENTO (¬°DEBES EDITAR ESTO!)\n",
        "# =================================================================\n",
        "def preprocess_input(data: 'InputData'):\n",
        "    \"\"\"\n",
        "    Esta funci√≥n toma los datos del formulario y los convierte\n",
        "    en el formato exacto que tu modelo Random Forest espera.\n",
        "    (Probablemente un array de NumPy con valores num√©ricos).\n",
        "\n",
        "    DEBES REPLICAR LA L√ìGICA DE TU NOTEBOOK DE ENTRENAMIENTO AQU√ç.\n",
        "    \"\"\"\n",
        "    # 1. Sube tus encoders/scalers (ej. 'encoder_comuna.joblib') a Colab\n",
        "    # 2. C√°rgalos aqu√≠:\n",
        "    # try:\n",
        "    #     encoder_comuna = joblib.load(\"encoder_comuna.joblib\")\n",
        "    #     encoder_tipo_acc = joblib.load(\"encoder_tipo_accidente.joblib\")\n",
        "    # except Exception as e:\n",
        "    #     raise HTTPException(status_code=500, detail=f\"Error al cargar encoders: {e}\")\n",
        "\n",
        "    # 3. Crea un DataFrame con los datos\n",
        "    df = pd.DataFrame([data.dict()])\n",
        "\n",
        "    # 4. Aplica las transformaciones (ejemplo):\n",
        "    # try:\n",
        "    #     df['Comuna_num'] = encoder_comuna.transform(df['Comuna'])\n",
        "    #     df['Tipo_accidente_num'] = encoder_tipo_acc.transform(df['Tipo_de_accidente'])\n",
        "    #     # ... (transforma Calle_uno, Calle_dos, Mes) ...\n",
        "    # except Exception as e:\n",
        "    #     raise HTTPException(status_code=400, detail=f\"Valor inv√°lido: {e}\")\n",
        "\n",
        "    # 5. Aseg√∫rate de que las columnas est√©n en el ORDEN EXACTO del entrenamiento\n",
        "    # columnas_ordenadas = ['Comuna_num', 'Calle_uno_num', 'Calle_dos_num', 'Tipo_accidente_num', 'Mes']\n",
        "    # features_finales = df[columnas_ordenadas].values\n",
        "\n",
        "    # --- Simulaci√≥n (Borra esto y reempl√°zalo con tu l√≥gica) ---\n",
        "    print(\"ADVERTENCIA: Usando pre-procesamiento simulado.\")\n",
        "    # Asumimos 5 features num√©ricos en el orden correcto\n",
        "    features_finales = np.array([[10, 5, 3, 1, 1]]) # Simulaci√≥n\n",
        "    # --- Fin Simulaci√≥n ---\n",
        "\n",
        "    return features_finales\n",
        "\n",
        "# --- Modelos Pydantic (Definici√≥n de datos) ---\n",
        "# Esto coincide con los features que me diste\n",
        "class InputData(BaseModel):\n",
        "    Calle_Uno: str\n",
        "    Calle_Dos: str\n",
        "    Comuna: str\n",
        "    Tipo_Accid: str\n",
        "    # Agregu√© 'Mes' porque lo pediste en tu descripci√≥n (\"en tal fecha\")\n",
        "    Mes: int = 1\n",
        "\n",
        "class PredictionResponse(BaseModel):\n",
        "    score: float # La r√∫brica pide {\"score\": float, ...}\n",
        "    drivers: List[str] # La r√∫brica pide {..., \"drivers\": [top_features]}\n",
        "\n",
        "class CoachInput(BaseModel):\n",
        "    ubicacion: str\n",
        "    score: float\n",
        "    drivers: List[str]\n",
        "\n",
        "class CoachResponse(BaseModel):\n",
        "    plan_textual: str\n",
        "    citas: List[str]\n",
        "\n",
        "# --- Endpoint 1: /predict (Tu Modelo ML) ---\n",
        "@app.post(\"/predict\", response_model=PredictionResponse)\n",
        "async def predict_risk(data: InputData):\n",
        "    if model is None:\n",
        "        raise HTTPException(status_code=500, detail=\"Error Cr√≠tico: Modelo ML no cargado.\")\n",
        "\n",
        "    try:\n",
        "        # 1. Procesa los datos del formulario al formato del modelo\n",
        "        features_procesados = preprocess_input(data)\n",
        "\n",
        "        # 2. Llama a tu modelo para obtener la probabilidad (score)\n",
        "        # Asumimos que tu target \"Frecuencia\" (ej. \"Muy Frecuente\") es la √∫ltima clase\n",
        "        score = model.predict_proba(features_procesados)[0][-1]\n",
        "\n",
        "        # =================================================================\n",
        "        # 2. IDENTIFICAR DRIVERS (¬°DEBES EDITAR ESTO!)\n",
        "        # =================================================================\n",
        "        # La r√∫brica pide \"top_features\".\n",
        "        # La forma simple es devolver los inputs que no son vac√≠os.\n",
        "        drivers = [f\"Comuna: {data.Comuna}\", f\"Tipo: {data.Tipo_de_accidente}\", f\"Intersecci√≥n: {data.Calle_uno} y {data.Calle_dos}\"]\n",
        "\n",
        "        return PredictionResponse(score=score, drivers=drivers)\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Error en predicci√≥n: {e}\")\n",
        "\n",
        "# --- Endpoint 2: /coach (Tu Chatbot RAG) ---\n",
        "@app.post(\"/coach\", response_model=CoachResponse)\n",
        "async def get_coach_plan(data: CoachInput):\n",
        "    # (El c√≥digo de RAG no cambia)\n",
        "    if openai.api_key is None:\n",
        "        raise HTTPException(status_code=500, detail=\"OPENAI_API_KEY no configurada\")\n",
        "\n",
        "    query_rag = \" \".join(data.drivers).replace(\"_\", \" \")\n",
        "    contexto_encontrado = buscar_en_kb(query_rag, top_k=2)\n",
        "\n",
        "    if not contexto_encontrado:\n",
        "        return CoachResponse(plan_textual=\"No se encontr√≥ informaci√≥n en la base de conocimiento /kb para estos factores de riesgo.\", citas=[])\n",
        "\n",
        "    prompt_para_llm = get_coach_prompt(query_rag, contexto_encontrado)\n",
        "    citas_usadas = [doc['cita'] for doc in contexto_encontrado]\n",
        "\n",
        "    try:\n",
        "        client = openai.OpenAI(api_key=openai.api_key)\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt_para_llm}],\n",
        "            temperature=0.0\n",
        "        )\n",
        "        plan_generado = response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error al llamar a OpenAI: {str(e)}\")\n",
        "\n",
        "    return CoachResponse(\n",
        "        plan_textual=plan_generado,\n",
        "        citas=citas_usadas\n",
        "    )\n",
        "\n",
        "# Endpoint de verificaci√≥n (para la Celda 9)\n",
        "@app.get(\"/\")\n",
        "def health_check():\n",
        "    return {\"status\": \"API funcionando!\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uACAeQNAxmfM",
        "outputId": "a5b08e3b-bbe5-4e61-c8a0-6a9ee997b079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting api/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Celda 8: app/app.py (La App de Streamlit) ---\n",
        "%%writefile app/app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- Conexi√≥n Autom√°tica a la API ---\n",
        "try:\n",
        "    with open(\"api_url.txt\", \"r\") as f:\n",
        "        API_URL = f.read().strip()\n",
        "    if not API_URL.startswith(\"http\"):\n",
        "        raise FileNotFoundError\n",
        "except FileNotFoundError:\n",
        "    API_URL = \"\"\n",
        "# --- Fin Conexi√≥n ---\n",
        "\n",
        "st.set_page_config(page_title=\"Optimizador de Rutas\", layout=\"wide\")\n",
        "st.title(\"üèôÔ∏è Optimizador de Rutas - Desaf√≠o Smart Cities Duoc UC\")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"Formulario de An√°lisis de Riesgo\")\n",
        "\n",
        "    # =================================================================\n",
        "    # Formulario con TUS features\n",
        "    # =================================================================\n",
        "    Comuna = st.text_input(\"Comuna\", \"Providencia\")\n",
        "    Calle_uno = st.text_input(\"Calle 1 (ej. Av. Providencia)\", \"Av. Providencia\")\n",
        "    Calle_dos = st.text_input(\"Calle 2 (ej. Av. Suecia)\", \"Av. Suecia\")\n",
        "    Tipo_de_accidente = st.selectbox(\"Tipo de Accidente\",\n",
        "                                     [\"Colisi√≥n\", \"Atropello\", \"Volcamiento\", \"Otro\"])\n",
        "    Mes = st.slider(\"Mes del a√±o\", 1, 12, 1)\n",
        "\n",
        "    submit_button = st.button(\"Analizar Riesgo\")\n",
        "\n",
        "if submit_button:\n",
        "    if not API_URL:\n",
        "        st.error(\"Error: La API (Celda 9) no est√° corriendo. Ejec√∫tala y luego reinicia esta app.\")\n",
        "    else:\n",
        "        # 1. Preparar los datos del formulario para la API\n",
        "        input_data_predict = {\n",
        "            \"Calle_uno\": Calle_uno,\n",
        "            \"Calle_dos\": Calle_dos,\n",
        "            \"Comuna\": Comuna,\n",
        "            \"Tipo_de_accidente\": Tipo_de_accidente,\n",
        "            \"Mes\": Mes\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # --- 2. Llamar al Endpoint /predict ---\n",
        "            with st.spinner(f\"1/2 - Contactando API en {API_URL}...\"):\n",
        "                response_predict = requests.post(f\"{API_URL}/predict\", json=input_data_predict, timeout=10)\n",
        "\n",
        "            if response_predict.status_code == 200:\n",
        "                data_predict = response_predict.json()\n",
        "                score = data_predict['score']\n",
        "                drivers = data_predict['drivers']\n",
        "\n",
        "                st.subheader(\"Resultado del An√°lisis de Riesgo\")\n",
        "                st.metric(\"Score de Riesgo (Probabilidad de Frecuencia Alta)\", f\"{score*100:.1f}%\")\n",
        "                st.warning(f\"**Factores Clave (Drivers):** {', '.join(drivers)}\")\n",
        "\n",
        "                # --- 3. Llamar al Endpoint /coach ---\n",
        "                with st.spinner(\"2/2 - Contactando al Coach IA (LLM+RAG)...\"):\n",
        "                    # Usamos la 'Comuna' como ubicaci√≥n para el coach\n",
        "                    input_data_coach = {\"ubicacion\": Comuna, \"score\": score, \"drivers\": drivers}\n",
        "                    response_coach = requests.post(f\"{API_URL}/coach\", json=input_data_coach, timeout=30)\n",
        "\n",
        "                    if response_coach.status_code == 200:\n",
        "                        data_coach = response_coach.json()\n",
        "                        st.subheader(\"Plan de Acci√≥n Sugerido (Coach IA)\")\n",
        "                        st.markdown(data_coach['plan_textual'])\n",
        "                        st.markdown(\"---\")\n",
        "                        st.markdown(f\"**Fuentes (desde /kb):** {', '.join(data_coach['citas'])}\")\n",
        "                    else:\n",
        "                        st.error(f\"Error en API /coach: {response_coach.text}\")\n",
        "            else:\n",
        "                st.error(f\"Error en API /predict: {response_predict.text}\")\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            st.error(f\"Error de Conexi√≥n: No se pudo conectar a la API en {API_URL}.\")\n",
        "            st.warning(\"La API (Celda 9) parece haberse 'dormido'. Reinicia la Celda 9 y luego refresca esta p√°gina.\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Ocurri√≥ un error inesperado: {e}\")\n",
        "\n",
        "# Disclaimer obligatorio por la r√∫brica\n",
        "st.sidebar.markdown(\"---\")\n",
        "st.sidebar.caption(\"Disclaimer: Esta es una demo para la Hackathon Duoc UC 2025. Los resultados son generados por IA y no constituyen un plan de acci√≥n profesional.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEtnMfOMx2rz",
        "outputId": "4d6f35ee-6873-487c-e7ea-02bab5d0fd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Celda 7: api/main.py (Versi√≥n \"Limpia\" de EMERGENCIA) ---\n",
        "%%writefile api/main.py\n",
        "import os\n",
        "import sys\n",
        "import joblib # A√∫n lo necesitamos para el modelo principal\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Any\n",
        "from google.colab import userdata\n",
        "import numpy as np # Necesario para el array simulado\n",
        "import pandas as pd\n",
        "\n",
        "# A√±adimos /content al path para que pueda encontrar 'src'\n",
        "sys.path.append('/content')\n",
        "from src.rag import buscar_en_kb\n",
        "from src.prompts import get_coach_prompt\n",
        "import openai\n",
        "\n",
        "# --- Configuraci√≥n y Carga de Modelos ---\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if openai.api_key is None: raise ValueError(\"Key no encontrada\")\n",
        "    print(\"OpenAI API Key cargada.\")\n",
        "except:\n",
        "    print(\"ERROR: No se encontr√≥ el Secret 'OPENAI_API_KEY'.\")\n",
        "\n",
        "app = FastAPI(title=\"Optimizador de Rutas - Hackathon Duoc UC\")\n",
        "\n",
        "# --- Carga de Modelo (Opcional) ---\n",
        "# Intentamos cargar el modelo, pero si falla, no importa.\n",
        "try:\n",
        "    model = joblib.load(\"modelo_riesgo.joblib\")\n",
        "    print(\"‚úÖ Modelo ML (modelo_riesgo.joblib) cargado.\")\n",
        "except Exception as e:\n",
        "    model = None\n",
        "    print(f\"üö® ADVERTENCIA AL CARGAR MODELO: {e}. Se usar√° simulaci√≥n.\")\n",
        "\n",
        "# --- Modelos Pydantic (Definici√≥n de datos) ---\n",
        "# Siguen siendo necesarios para que el formulario env√≠e datos\n",
        "class InputData(BaseModel):\n",
        "    Calle_uno: str\n",
        "    Calle_dos: str\n",
        "    Comuna: str\n",
        "    Tipo_de_accidente: str\n",
        "    Mes: int = 1\n",
        "\n",
        "class PredictionResponse(BaseModel):\n",
        "    score: float\n",
        "    drivers: List[str]\n",
        "\n",
        "class CoachInput(BaseModel):\n",
        "    ubicacion: str\n",
        "    score: float\n",
        "    drivers: List[str]\n",
        "\n",
        "class CoachResponse(BaseModel):\n",
        "    plan_textual: str\n",
        "    citas: List[str]\n",
        "\n",
        "# =================================================================\n",
        "# --- Endpoint 1: /predict (¬°VERSI√ìN SIMULADA!) ---\n",
        "# =================================================================\n",
        "@app.post(\"/predict\", response_model=PredictionResponse)\n",
        "async def predict_risk(data: InputData):\n",
        "\n",
        "    # Como est√°s contra el tiempo, nos saltamos el pre-procesamiento\n",
        "    # y el modelo real.\n",
        "\n",
        "    print(\"--- Ejecutando /predict en MODO DE EMERGENCIA (SIMULACI√ìN) ---\")\n",
        "\n",
        "    # 1. Devolvemos un score (probabilidad) FALSO\n",
        "    score_simulado = 0.658 # Un 65.8% de probabilidad\n",
        "\n",
        "    # 2. Devolvemos drivers FALSOS (basados en el input)\n",
        "    drivers_simulados = [f\"Comuna: {data.Comuna}\", f\"Tipo: {data.Tipo_de_accidente}\"]\n",
        "\n",
        "    return PredictionResponse(score=score_simulado, drivers=drivers_simulados)\n",
        "\n",
        "# --- Endpoint 2: /coach (Tu Chatbot RAG) ---\n",
        "# (Este endpoint no cambia, sigue funcionando)\n",
        "@app.post(\"/coach\", response_model=CoachResponse)\n",
        "async def get_coach_plan(data: CoachInput):\n",
        "    if openai.api_key is None:\n",
        "        raise HTTPException(status_code=500, detail=\"OPENAI_API_KEY no configurada\")\n",
        "\n",
        "    query_rag = \" \".join(data.drivers).replace(\"_\", \" \")\n",
        "    contexto_encontrado = buscar_en_kb(query_rag, top_k=2)\n",
        "\n",
        "    if not contexto_encontrado:\n",
        "        return CoachResponse(plan_textual=\"No se encontr√≥ informaci√≥n en la base de conocimiento /kb para estos factores de riesgo.\", citas=[])\n",
        "\n",
        "    prompt_para_llm = get_coach_prompt(query_rag, contexto_encontrado)\n",
        "    citas_usadas = [doc['cita'] for doc in contexto_encontrado]\n",
        "\n",
        "    try:\n",
        "        client = openai.OpenAI(api_key=openai.api_key)\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt_para_llm}],\n",
        "            temperature=0.0\n",
        "        )\n",
        "        plan_generado = response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error al llamar a OpenAI: {str(e)}\")\n",
        "\n",
        "    return CoachResponse(\n",
        "        plan_textual=plan_generado,\n",
        "        citas=citas_usadas\n",
        "    )\n",
        "\n",
        "# Endpoint de verificaci√≥n (para la Celda 9)\n",
        "@app.get(\"/\")\n",
        "def health_check():\n",
        "    return {\"status\": \"API funcionando!\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVBb3CcdzwEj",
        "outputId": "ddbaeb5e-539f-467a-95f0-f9bf3b6ce4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting api/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- Conexi√≥n Autom√°tica a la API ---\n",
        "# Esta secci√≥n lee el archivo 'api_url.txt' que la Celda 9 crear√°.\n",
        "try:\n",
        "    with open(\"api_url.txt\", \"r\") as f:\n",
        "        API_URL = f.read().strip()\n",
        "    if not API_URL.startswith(\"http\"):\n",
        "        raise FileNotFoundError\n",
        "except FileNotFoundError:\n",
        "    API_URL = \"\"  # Si no encuentra el archivo, se queda vac√≠o\n",
        "# --- Fin Conexi√≥n ---\n",
        "\n",
        "st.set_page_config(page_title=\"Optimizador de Rutas\", layout=\"wide\")\n",
        "st.title(\"üèôÔ∏è Optimizador de Rutas - Desaf√≠o Smart Cities Duoc UC\")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"Formulario de An√°lisis de Riesgo\")\n",
        "\n",
        "    # =================================================================\n",
        "    # Formulario con TUS features (debe coincidir con la Celda 7)\n",
        "    # =================================================================\n",
        "    Comuna = st.text_input(\"Comuna\", \"Providencia\")\n",
        "    Calle_uno = st.text_input(\"Calle 1 (ej. Av. Providencia)\", \"Av. Providencia\")\n",
        "    Calle_dos = st.text_input(\"Calle 2 (ej. Av. Suecia)\", \"Av. Suecia\")\n",
        "\n",
        "    # Aqu√≠ puedes poner los valores que tu encoder espera\n",
        "    Tipo_de_accidente = st.selectbox(\n",
        "        \"Tipo de Accidente\",\n",
        "        [\"Colisi√≥n\", \"Atropello\", \"Volcamiento\", \"Otro\"]\n",
        "    )\n",
        "\n",
        "    Mes = st.slider(\"Mes del a√±o\", 1, 12, 1)\n",
        "\n",
        "    submit_button = st.button(\"Analizar Riesgo\")\n",
        "\n",
        "# --- L√≥gica de la App ---\n",
        "if submit_button:\n",
        "    # Si la API (Celda 9) no se ha ejecutado, muestra un error\n",
        "    if not API_URL:\n",
        "        st.error(\"Error: La API (Celda 9) no est√° corriendo. Ejec√∫tala y luego reinicia esta app (Celda 10).\")\n",
        "    else:\n",
        "        # 1. Preparar los datos del formulario para la API\n",
        "        # (Los nombres deben coincidir con la 'InputData' de la Celda 7)\n",
        "        input_data_predict = {\n",
        "            \"Calle_uno\": Calle_uno,\n",
        "            \"Calle_dos\": Calle_dos,\n",
        "            \"Comuna\": Comuna,\n",
        "            \"Tipo_de_accidente\": Tipo_de_accidente,\n",
        "            \"Mes\": Mes\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # --- 2. Llamar al Endpoint /predict ---\n",
        "            with st.spinner(f\"1/2 - Contactando API en {API_URL}...\"):\n",
        "                response_predict = requests.post(\n",
        "                    f\"{API_URL}/predict\",\n",
        "                    json=input_data_predict,\n",
        "                    timeout=10\n",
        "                )\n",
        "\n",
        "            # Si la API responde OK\n",
        "            if response_predict.status_code == 200:\n",
        "                data_predict = response_predict.json()\n",
        "                score = data_predict['score']\n",
        "                drivers = data_predict['drivers']\n",
        "\n",
        "                st.subheader(\"Resultado del An√°lisis de Riesgo\")\n",
        "                st.metric(\"Score de Riesgo (Probabilidad de Frecuencia Alta)\", f\"{score*100:.1f}%\")\n",
        "\n",
        "                # --- Implementaci√≥n de Guardrail (R√∫brica B3) ---\n",
        "                UMBRAL_CRITICO = 0.75  # Define tu umbral\n",
        "                if score > UMBRAL_CRITICO:\n",
        "                    st.error(\n",
        "                        f\"**ALERTA (Guardrail):** El riesgo ({score*100:.1f}%) supera el umbral cr√≠tico de \"\n",
        "                        f\"{UMBRAL_CRITICO*100}%. Se recomienda derivar a un profesional para an√°lisis detallado.\"\n",
        "                    )\n",
        "\n",
        "                # Esta l√≠nea estaba duplicada y mal indentada en tu original\n",
        "                st.warning(f\"**Factores Clave (Drivers):** {', '.join(drivers)}\")\n",
        "\n",
        "                # --- 3. Llamar al Endpoint /coach ---\n",
        "                with st.spinner(\"2/2 - Contactando al Coach IA (LLM+RAG)...\"):\n",
        "                    input_data_coach = {\"ubicacion\": Comuna, \"score\": score, \"drivers\": drivers}\n",
        "                    response_coach = requests.post(\n",
        "                        f\"{API_URL}/coach\",\n",
        "                        json=input_data_coach,\n",
        "                        timeout=30\n",
        "                    )\n",
        "\n",
        "                    if response_coach.status_code == 200:\n",
        "                        data_coach = response_coach.json()\n",
        "                        st.subheader(\"Plan de Acci√≥n Sugerido (Coach IA)\")\n",
        "                        st.markdown(data_coach['plan_textual'])\n",
        "                        st.markdown(\"---\")\n",
        "                        st.markdown(f\"**Fuentes (desde /kb):** {', '.join(data_coach['citas'])}\")\n",
        "                    else:\n",
        "                        st.error(f\"Error en API /coach: {response_coach.text}\")\n",
        "            else:\n",
        "                # Muestra el error si /predict falla\n",
        "                st.error(f\"Error en API /predict: {response_predict.text}\")\n",
        "\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            st.error(f\"Error de Conexi√≥n: No se pudo conectar a la API en {API_URL}.\")\n",
        "            st.warning(\"La API (Celda 9) parece haberse 'dormido'. Reinicia la Celda 9 y luego refresca esta p√°gina.\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Ocurri√≥ un error inesperado: {e}\")\n",
        "\n",
        "# Disclaimer obligatorio por la r√∫brica\n",
        "st.sidebar.markdown(\"---\")\n",
        "st.sidebar.caption(\"Disclaimer: Esta es una demo para la Hackathon Duoc UC 2025. Los resultados son generados por IA y no constituyen un plan de acci√≥n profesional.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFySpAgyzypk",
        "outputId": "192989f0-7086-41c1-bc26-6e22fccaba44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-07 09:40:39.252 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.254 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.374 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-11-07 09:40:39.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.381 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.383 Session state does not function when running a script without `streamlit run`\n",
            "2025-11-07 09:40:39.385 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.385 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.386 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.389 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.407 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.408 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.410 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.410 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.412 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.413 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.414 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.414 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.418 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.419 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.420 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-07 09:40:39.421 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator(_root_container=1, _parent=DeltaGenerator())"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Celda 9: Lanzar la API (Backend) ---\n",
        "import os\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "\n",
        "print(\"--- 1. Matando cualquier API 'zombie' anterior... ---\")\n",
        "!pkill -f uvicorn\n",
        "!pkill -f ngrok  # <-- ¬°CORRECCI√ìN para el error de 'simultaneous session'!\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"--- 2. Cargando secretos (tokens)... ---\")\n",
        "try:\n",
        "    ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "    if ngrok_token is None: raise ValueError(\"Token no encontrado\")\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "    print(\"‚úÖ Ngrok Authtoken cargado.\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® ERROR FATAL al cargar NGROK_AUTH_TOKEN: {e}\")\n",
        "    raise e\n",
        "\n",
        "print(\"--- 3. Lanzando la API (Backend)... ---\")\n",
        "command = \"PYTHONPATH=$PYTHONPATH:/content uvicorn api.main:app --host 0.0.0.0 --port 8000 &\"\n",
        "get_ipython().system_raw(command)\n",
        "time.sleep(5) # Dale tiempo a Uvicorn para que inicie\n",
        "\n",
        "print(\"--- 4. Verificando si la API (Backend) se inici√≥... ---\")\n",
        "try:\n",
        "    response = requests.get(\"http://127.0.0.1:8000/\") # Llama al endpoint de health check (/)\n",
        "    if response.status_code != 200:\n",
        "       raise Exception(f\"La API no respondi√≥ correctamente. C√≥digo: {response.status_code}\")\n",
        "    print(\"‚úÖ ¬°√âxito! La API (Backend) est√° corriendo localmente.\")\n",
        "except requests.exceptions.ConnectionError:\n",
        "    print(\"üö® ERROR FATAL: No se pudo conectar a la API (http://127.0.0.1:8000/).\")\n",
        "    print(\"üõë Revisa los 'Secrets' (OPENAI_API_KEY) y si subiste tu 'modelo_riesgo.joblib' y tus 4 encoders.\")\n",
        "    raise Exception(\"Fallo al iniciar Uvicorn.\")\n",
        "\n",
        "print(\"--- 5. Creando t√∫nel p√∫blico (Ngrok) y guardando URL... ---\")\n",
        "try:\n",
        "    public_url = ngrok.connect(8000)\n",
        "    with open(\"api_url.txt\", \"w\") as f:\n",
        "        f.write(str(public_url))\n",
        "    print(f\"‚úÖ URL guardada en api_url.txt\")\n",
        "\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "    print(f\"URL P√öBLICA DE TU API: {public_url}\")\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "    print(\"‚úÖ ¬°LISTO! Ahora puedes ejecutar la Celda 10 (la App).\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® ERROR FATAL al conectar con ngrok: {e}\")\n",
        "    print(\"üõë Revisa tu cuenta de ngrok si el error persiste.\")\n",
        "    raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TvQuBz-8jhe",
        "outputId": "5c77b1aa-e40e-4be0-8af7-c9d3cccc3208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Matando cualquier API 'zombie' anterior... ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-07T09:40:48+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-1cfceef0-2322-4590-b038-029f79ab41de acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2. Cargando secretos (tokens)... ---\n",
            "‚úÖ Ngrok Authtoken cargado.\n",
            "--- 3. Lanzando la API (Backend)... ---\n",
            "--- 4. Verificando si la API (Backend) se inici√≥... ---\n",
            "‚úÖ ¬°√âxito! La API (Backend) est√° corriendo localmente.\n",
            "--- 5. Creando t√∫nel p√∫blico (Ngrok) y guardando URL... ---\n",
            "‚úÖ URL guardada en api_url.txt\n",
            "-----------------------------------------------------------------\n",
            "URL P√öBLICA DE TU API: NgrokTunnel: \"https://brande-interpervasive-china.ngrok-free.dev\" -> \"http://localhost:8000\"\n",
            "-----------------------------------------------------------------\n",
            "‚úÖ ¬°LISTO! Ahora puedes ejecutar la Celda 10 (la App).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Celda 10: Lanzar la APP (Frontend) ---\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "print(\"--- 1. Matando cualquier app 'zombie' de Streamlit... ---\")\n",
        "!pkill -f streamlit\n",
        "!pkill -f ngrok  # <-- ¬°CORRECCI√ìN para el error de 'simultaneous session'!\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"--- 2. Lanzando la aplicaci√≥n Streamlit (en segundo plano)... ---\")\n",
        "command = \"streamlit run app/app.py --server.port 8501 &\"\n",
        "get_ipython().system_raw(command)\n",
        "time.sleep(5)\n",
        "\n",
        "print(\"--- 3. Creando t√∫nel p√∫blico (Ngrok) para la App... ---\")\n",
        "try:\n",
        "    app_url = ngrok.connect(8501)\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "    print(f\"¬°Tu APP ya est√° P√öBLICA!\")\n",
        "    print(f\"URL DE LA APLICACI√ìN: {app_url}\")\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "    print(\"‚úÖ ¬°LISTO! Abre esta URL en tu navegador para ver tu app.\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® ERROR FATAL al conectar ngrok al puerto 8501: {e}\")\n",
        "    raise e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXuw9Mwa87sV",
        "outputId": "f759e41e-eb60-49d3-ed6b-ebbe4227b723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Matando cualquier app 'zombie' de Streamlit... ---\n",
            "--- 2. Lanzando la aplicaci√≥n Streamlit (en segundo plano)... ---\n",
            "--- 3. Creando t√∫nel p√∫blico (Ngrok) para la App... ---\n",
            "-----------------------------------------------------------------\n",
            "¬°Tu APP ya est√° P√öBLICA!\n",
            "URL DE LA APLICACI√ìN: NgrokTunnel: \"https://brande-interpervasive-china.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "-----------------------------------------------------------------\n",
            "‚úÖ ¬°LISTO! Abre esta URL en tu navegador para ver tu app.\n"
          ]
        }
      ]
    }
  ]
}